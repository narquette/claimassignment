{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------ Import Modules ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T15:33:12.764551Z",
     "start_time": "2020-07-31T15:33:10.126193Z"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import json\n",
    "from machine_learning import MachineLearning, random_tune, xgb_tune, lgb_tune, xgb, lgb\n",
    "from config import GetDict, SetDict\n",
    "from feature_importance import FeatureImportance\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------ Create Models ------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Line Model (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T15:33:14.601711Z",
     "start_time": "2020-07-31T15:33:14.066203Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muniques\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c4bbb6de6dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# perform logistic regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# print out mean squared error and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmachine_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The mean squared error is {mse} and accuracy is {score}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/claimassignment/code/machine_learning.py\u001b[0m in \u001b[0;36mLogisticRegression\u001b[0;34m(self, cross_validation, prediction, save_model)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;31m# return best score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/claimassignment/code/machine_learning.py\u001b[0m in \u001b[0;36mScoring\u001b[0;34m(self, save_model)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;31m# Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;31m# save model if save_mode is True:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[1;32m    465\u001b[0m                     message=self._log_message(name, idx, len(transformers)))\n\u001b[1;32m    466\u001b[0m                 for idx, (name, trans, column, weight) in enumerate(\n\u001b[0;32m--> 467\u001b[0;31m                         self._iter(fitted=fitted, replace_strings=True), 1))\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"Expected 2D array, got 1D array instead\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 return last_step.fit(Xt, y,\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \"\"\"\n\u001b[1;32m    409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \"\"\"\n\u001b[1;32m    384\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_idx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_drop_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, handle_unknown)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mXi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mcats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mcats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/claims/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[1;32m    115\u001b[0m             types = sorted(t.__qualname__\n\u001b[1;32m    116\u001b[0m                            for t in set(type(v) for v in values))\n\u001b[0;32m--> 117\u001b[0;31m             raise TypeError(\"Encoders require their input to be uniformly \"\n\u001b[0m\u001b[1;32m    118\u001b[0m                             f\"strings or numbers. Got {types}\")\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']"
     ]
    }
   ],
   "source": [
    "# store name to be use in results\n",
    "model = 'LogisticRegression'\n",
    "\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}\"),\n",
    "                                   imbalance=True)\n",
    "\n",
    "# set up pre-processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# perform logistic regression\n",
    "# print out mean squared error and accuracy\n",
    "mse, score = machine_learning.LogisticRegression()\n",
    "\n",
    "print(f\"The mean squared error is {mse} and accuracy is {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T03:38:17.832362Z",
     "start_time": "2020-07-15T03:38:17.830038Z"
    }
   },
   "source": [
    "## Random Forest Classifier Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.424138Z",
     "start_time": "2020-07-31T14:23:54.627Z"
    }
   },
   "outputs": [],
   "source": [
    "# store name to be use in results\n",
    "model = 'RandomForest'\n",
    "\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}\"),\n",
    "                                   imbalance=True)\n",
    "\n",
    "# set up pre-processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# store results as a list of tuples\n",
    "results = []\n",
    "\n",
    "# loop through each paramter and parameter value\n",
    "for key, values in random_tune.items():\n",
    "    # loop through each \n",
    "    for value in values:\n",
    "        \n",
    "        # set parameter and value to tune\n",
    "        parameter = { key : value }\n",
    "        \n",
    "        # perform random forst\n",
    "        score = machine_learning.RandomForest(parameter_dict=parameter, regressor=False)\n",
    "        \n",
    "        results.append((key, value, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.425480Z",
     "start_time": "2020-07-31T14:23:54.630Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# store best result to be used as parameter\n",
    "best_results_dict = {}\n",
    "\n",
    "# loop through all parameter keys\n",
    "for key in random_tune.keys():\n",
    "    \n",
    "    # get the values for current key\n",
    "    values = [val for val in results if val[0] == key]\n",
    "    # get the score for current key\n",
    "    scores = [val[2] for val in values]\n",
    "    # get parameter for current key and max score\n",
    "    best_score = [val for val in values if val[2] == min(scores)]\n",
    "    # set diction with best parameter and parameter value\n",
    "    best_results_dict[best_score[0][0]] = best_score[0][1]\n",
    "    \n",
    "# print best result\n",
    "print(best_results_dict)\n",
    "    \n",
    "# write results to file\n",
    "file_name = f\"{model}_best_results_dict.json\"\n",
    "json_data = json.dumps(best_results_dict)\n",
    "SetDict(file_name,json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T03:49:27.925265Z",
     "start_time": "2020-07-15T03:49:27.916470Z"
    }
   },
   "source": [
    "### Final, Tuned, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.426485Z",
     "start_time": "2020-07-31T14:23:54.633Z"
    }
   },
   "outputs": [],
   "source": [
    "# store name to be use in results\n",
    "model = 'RandomForest'\n",
    "\n",
    "# call machine learning class\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}\"),\n",
    "                                   imbalance=True)\n",
    "# setup pre processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# get best_results_dict\n",
    "best_results_dict = GetDict(f\"{model}_best_results_dict.json\")  \n",
    "\n",
    "# perform random forest using best parameters\n",
    "mse, score = machine_learning.RandomForest(regressor=False, parameter_dict=best_results_dict)\n",
    "\n",
    "# print final model score\n",
    "print(f\"The mean squared error is {mse} and accuracy is {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.428032Z",
     "start_time": "2020-07-31T14:23:54.636Z"
    }
   },
   "outputs": [],
   "source": [
    "# set model name\n",
    "model = 'XGBoost'\n",
    "\n",
    "# call machine learning class\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}\"),\n",
    "                                   imbalance=True)\n",
    "\n",
    "# perform pre-processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# store results as a list of tuples\n",
    "results = []\n",
    "\n",
    "# loop through each paramter and parameter value\n",
    "for key, values in xgb_tune.items():\n",
    "    # loop through each\n",
    "    for value in values:\n",
    "\n",
    "        # set parameter and value to tune\n",
    "        parameter = {key: value}\n",
    "\n",
    "        # perform random forst\n",
    "        score = machine_learning.XGboost(regressor=False, parameter_dict=parameter)\n",
    "\n",
    "        results.append((key, value, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.429859Z",
     "start_time": "2020-07-31T14:23:54.640Z"
    }
   },
   "outputs": [],
   "source": [
    "# store best result to be used as parameter\n",
    "best_results_dict = {}\n",
    "\n",
    "# loop through all parameter keys\n",
    "for key in xgb_tune.keys():\n",
    "\n",
    "    # get the values for current key\n",
    "    values = [val for val in results if val[0] == key]\n",
    "    # get the score for current key\n",
    "    scores = [val[2] for val in values]\n",
    "    # get parameter for current key and max score\n",
    "    best_score = [val for val in values if val[2] == min(scores)]\n",
    "    # set diction with best parameter and parameter value\n",
    "    best_results_dict[best_score[0][0]] = best_score[0][1]\n",
    "\n",
    "# print out results\n",
    "print(best_results_dict)\n",
    "\n",
    "# write results to file\n",
    "file_name = f\"{model}_best_results_dict.json\"\n",
    "json_data = json.dumps(best_results_dict)\n",
    "SetDict(file_name,json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final, Tuned, XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.431600Z",
     "start_time": "2020-07-31T14:23:54.644Z"
    }
   },
   "outputs": [],
   "source": [
    "# set model name\n",
    "model = 'XGBoost' \n",
    "\n",
    "# call machine learning class\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}\"),\n",
    "                                   imbalance=True)\n",
    " \n",
    "# setup pre processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# get best_results_dict\n",
    "best_results_dict = GetDict(f\"{model}_best_results_dict.json\")\n",
    "\n",
    "\n",
    "# # perform random forest using best parameters\n",
    "mse, score = machine_learning.XGboost(regressor=False, parameter_dict=best_results_dict)\n",
    "        \n",
    "# # print final model score\n",
    "print(mse, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LgBoost Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.433243Z",
     "start_time": "2020-07-31T14:23:54.648Z"
    }
   },
   "outputs": [],
   "source": [
    "# set model name\n",
    "model = 'LGBoost'\n",
    "\n",
    "# call machine learning class\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}\"),\n",
    "                                   imbalance=True)\n",
    " \n",
    "# set columns for preprocessing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# store results as a list of tuples\n",
    "results = []\n",
    "\n",
    "# loop through each paramter and parameter value\n",
    "for key, values in lgb_tune.items():\n",
    "    # loop through each \n",
    "    for value in values:\n",
    "        \n",
    "        # set parameter and value to tune\n",
    "        parameter = { key : value }\n",
    "        \n",
    "        # perform random forst\n",
    "        score = machine_learning.LGboost(regressor=False, parameter_dict=parameter)\n",
    "        \n",
    "        results.append((key, value, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.434594Z",
     "start_time": "2020-07-31T14:23:54.650Z"
    }
   },
   "outputs": [],
   "source": [
    "# store best result to be used as parameter\n",
    "best_results_dict = {}\n",
    "\n",
    "# loop through all parameter keys\n",
    "for key in lgb_tune.keys():\n",
    "\n",
    "    # get the values for current key\n",
    "    values = [val for val in results if val[0] == key]\n",
    "    # get the score for current key\n",
    "    scores = [val[2] for val in values]\n",
    "    # get parameter for current key and max score\n",
    "    best_score = [val for val in values if val[2] == min(scores)]\n",
    "    # set diction with best parameter and parameter value\n",
    "    best_results_dict[best_score[0][0]] = best_score[0][1]\n",
    "\n",
    "# print out results\n",
    "print(best_results_dict)\n",
    "\n",
    "# write results to file\n",
    "file_name = f\"{model}_best_results_dict.json\"\n",
    "json_data = json.dumps(best_results_dict)\n",
    "SetDict(file_name,json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final, Tuned, LgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.435552Z",
     "start_time": "2020-07-31T14:23:54.653Z"
    }
   },
   "outputs": [],
   "source": [
    "# set model name\n",
    "model = 'LGBoost' \n",
    "\n",
    "# call machine learning class\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}\"),\n",
    "                                   imbalance=True)\n",
    " \n",
    "# setup pre processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# get best_results_dict\n",
    "best_results_dict = GetDict(f\"{model}_best_results_dict.json\")  \n",
    "\n",
    "\n",
    "# perform random forest using best parameters\n",
    "score, mse = machine_learning.LGboost(regressor=False, parameter_dict=best_results_dict)\n",
    "        \n",
    "# print final model score\n",
    "print(score, mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------ Test Models ------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.436592Z",
     "start_time": "2020-07-31T14:23:54.657Z"
    }
   },
   "outputs": [],
   "source": [
    "# store name to be use in results\n",
    "model = 'LogisticRegression'\n",
    "\n",
    "# store results for all models\n",
    "cv_results = {}\n",
    "\n",
    "# load data\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}_CrossValidation\"),\n",
    "                                   imbalance=True)\n",
    "\n",
    "# setup pre processing\n",
    "preprocessing=machine_learning.PreProcessing()\n",
    "\n",
    "# perform random forest using best parameters\n",
    "mse = machine_learning.LogisticRegression(cross_validation=True)\n",
    "\n",
    "# get minimum mse value index\n",
    "index = np.argmin(mse[0])\n",
    "\n",
    "# get minimum mse and corresponding accuracy\n",
    "min_mse = mse[0][index]\n",
    "min_accuracy = mse[1][index]\n",
    "\n",
    "# store final model score\n",
    "cv_results[model] = min_mse, min_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.438348Z",
     "start_time": "2020-07-31T14:23:54.662Z"
    }
   },
   "outputs": [],
   "source": [
    "# store name to be use in results\n",
    "model = 'RandomForest'\n",
    "\n",
    "# load data\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}_CrossValidation\"),\n",
    "                                   imbalance=True)\n",
    "\n",
    "# setup pre processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# get best_results_dict\n",
    "best_results_dict = GetDict(f\"{model}_best_results_dict.json\")  \n",
    "\n",
    "# perform random forest using best parameters\n",
    "mse = machine_learning.RandomForest(\n",
    "    parameter_dict=best_results_dict, regressor=False, cross_validation=True)\n",
    "\n",
    "# get minimum mse value index\n",
    "index = np.argmin(mse[0])\n",
    "\n",
    "# get minimum mse and corresponding accuracy\n",
    "min_mse = mse[0][index]\n",
    "min_accuracy = mse[1][index]\n",
    "\n",
    "# store final model score\n",
    "cv_results[model] = min_mse, min_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T04:29:53.743096Z",
     "start_time": "2020-07-15T04:29:53.740031Z"
    }
   },
   "source": [
    "## XgBoost Forest Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.440007Z",
     "start_time": "2020-07-31T14:23:54.665Z"
    }
   },
   "outputs": [],
   "source": [
    "# store name to be use in results\n",
    "model = 'XGBoost'\n",
    "\n",
    "# load data\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}_CrossValidation\"),\n",
    "                                   imbalance=True)\n",
    "\n",
    "# setup pre processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# get best_results_dict\n",
    "best_results_dict = GetDict(f\"{model}_best_results_dict.json\")  \n",
    "\n",
    "# perform random forest using best parameters\n",
    "mse = machine_learning.XGboost(\n",
    "    parameter_dict=best_results_dict, regressor=False, cross_validation=True)\n",
    "\n",
    "# get minimum mse value index\n",
    "index = np.argmin(mse[0])\n",
    "\n",
    "# get minimum mse and corresponding accuracy\n",
    "min_mse = mse[0][index]\n",
    "min_accuracy = mse[1][index]\n",
    "\n",
    "# store final model score\n",
    "cv_results[model] = min_mse, min_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LgBoost Forest Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.441819Z",
     "start_time": "2020-07-31T14:23:54.669Z"
    }
   },
   "outputs": [],
   "source": [
    "# store name to be use in results\n",
    "model = 'LGBoost'\n",
    "\n",
    "# load data\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}_CrossValidation\"),\n",
    "                                   imbalance=True)\n",
    "\n",
    "# setup pre processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# get best_results_dict\n",
    "best_results_dict = GetDict(f\"{model}_best_results_dict.json\")  \n",
    "\n",
    "# perform random forest using best parameters\n",
    "mse = machine_learning.LGboost(\n",
    "    parameter_dict=best_results_dict, regressor=False, cross_validation=True)\n",
    "\n",
    "# get minimum mse value index\n",
    "index = np.argmin(mse[0])\n",
    "\n",
    "# get minimum mse and corresponding accuracy\n",
    "min_mse = mse[0][index]\n",
    "min_accuracy = mse[1][index]\n",
    "\n",
    "# store final model score\n",
    "cv_results[model] = min_mse, min_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.443676Z",
     "start_time": "2020-07-31T14:23:54.676Z"
    }
   },
   "outputs": [],
   "source": [
    "# show model results\n",
    "model_dataframe = pd.DataFrame()\n",
    "model_dataframe['Model'] = cv_results.keys()\n",
    "model_dataframe['MeanSquaredError'] = [v[0] for v in cv_results.values()]\n",
    "model_dataframe['Accuracy'] = [v[1] for v in cv_results.values()]\n",
    "model_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.445430Z",
     "start_time": "2020-07-31T14:23:54.679Z"
    }
   },
   "outputs": [],
   "source": [
    "# write dataframe to file\n",
    "model_dataframe.to_csv(os.path.join('../logs','FinalResults.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T04:34:27.756703Z",
     "start_time": "2020-07-15T04:34:27.753878Z"
    }
   },
   "source": [
    "## Select best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.447654Z",
     "start_time": "2020-07-31T14:23:54.683Z"
    }
   },
   "outputs": [],
   "source": [
    "#select the model with the lowest error as your \"production\" model\n",
    "model_dataframe = pd.read_csv(os.path.join('../logs', 'FinalResults.csv'), low_memory=False)\n",
    "best_model = model_dataframe.loc[model_dataframe['MeanSquaredError'] == min(model_dataframe['MeanSquaredError'])]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.449415Z",
     "start_time": "2020-07-31T14:23:54.685Z"
    }
   },
   "outputs": [],
   "source": [
    "# store name to be use in results\n",
    "model = best_model['Model'].to_string(index=False).strip()\n",
    "\n",
    "# load data\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}_FinalModel\"),\n",
    "                                   imbalance=True)\n",
    "\n",
    "# setup pre processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "if model == 'LogisticRegression':\n",
    "    machine_learning.LogisticRegression(save_model=True)\n",
    "elif model == 'RandomForest':\n",
    "    best_results_dict = GetDict(f\"{model}_best_results_dict.json\")  \n",
    "    machine_learning.RandomForest(\n",
    "        parameter_dict=best_results_dict, regressor=False, save_model=True)\n",
    "elif model == 'XGBoost':\n",
    "    best_results_dict = GetDict(f\"{model}_best_results_dict.json\")  \n",
    "    machine_learning.XGboost(parameter_dict=best_results_dict, regressor=False, save_model=True)\n",
    "elif model == 'LGBoost':\n",
    "    best_results_dict = GetDict(f\"{model}_best_results_dict.json\")  \n",
    "    machine_learning.LGboost(parameter_dict=best_results_dict, regressor=False, save_model=True)\n",
    "else:\n",
    "    print(f'{model} not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.451181Z",
     "start_time": "2020-07-31T14:23:54.688Z"
    }
   },
   "outputs": [],
   "source": [
    "# store name to be use in results\n",
    "model_name = best_model['Model'].to_string(index=False).strip()\n",
    "\n",
    "# plot feature importance for the best model\n",
    "FeatureImportance(model=model_name);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h2o Auto ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.453521Z",
     "start_time": "2020-07-31T14:23:54.691Z"
    }
   },
   "outputs": [],
   "source": [
    "# # initiate h2o\n",
    "# h2o.init()\n",
    "\n",
    "# # Import claims data (same split used in above modeling) set into H2O\n",
    "# train = h2o.import_file(os.path.join('../data', 'train_test_split', 'procedure_train_data.csv'))\n",
    "# test = h2o.import_file(os.path.join('../data', 'train_test_split', 'procedure_test_data.csv'))\n",
    "\n",
    "# # Identify predictors and response\n",
    "# x = train.columns\n",
    "# y = \"UnpaidClaim\"\n",
    "# x.remove(y)\n",
    "\n",
    "# # Run AutoML for 20 base models (limited to 1 hour max runtime by default)\n",
    "# # Exclude Stacked Ensemble models as they will not include Feature Importance\n",
    "# aml = H2OAutoML(max_models=20, seed=1, exclude_algos=['StackedEnsemble'])\n",
    "# aml.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "# # View the AutoML Leaderboard\n",
    "# lb = aml.leaderboard\n",
    "# lb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T14:23:56.455566Z",
     "start_time": "2020-07-31T14:23:54.694Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The leader model is stored here\n",
    "# aml.leader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (claims)",
   "language": "python",
   "name": "claims"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

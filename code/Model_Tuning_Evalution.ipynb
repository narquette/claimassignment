{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------ Import Modules ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T15:17:07.622901Z",
     "start_time": "2020-08-12T15:17:06.435482Z"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import json\n",
    "from machine_learning import MachineLearning, random_tune, xgb_tune, lgb_tune, xgb, lgb\n",
    "from config import GetDict, SetDict\n",
    "from feature_importance import FeatureImportance\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------ Create Models ------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Line Model (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T15:17:08.231824Z",
     "start_time": "2020-08-12T15:17:07.625155Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error is 0.08644198610753795 and accuracy is 0.913558013892462 and precision is 0.9388312397596942 and         recall is 0.8847143592382913 and f1 is 0.9109697933227344\n"
     ]
    }
   ],
   "source": [
    "# store name to be use in results\n",
    "model = 'LogisticRegression'\n",
    "\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}\"),\n",
    "                                   imbalance=True)\n",
    "\n",
    "# set up pre-processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# perform logistic regression\n",
    "# print out mean squared error and accuracy\n",
    "mse, score, report = machine_learning.LogisticRegression()\n",
    "\n",
    "print(f\"The mean squared error is {mse} and accuracy is {report['accuracy']} and precision is {report['1']['precision']} and \\\n",
    "        recall is {report['1']['recall']} and f1 is {report['1']['f1-score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T03:38:17.832362Z",
     "start_time": "2020-07-15T03:38:17.830038Z"
    }
   },
   "source": [
    "## Random Forest Classifier Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T15:17:38.171504Z",
     "start_time": "2020-08-12T15:17:08.234144Z"
    }
   },
   "outputs": [],
   "source": [
    "# store name to be use in results\n",
    "model = 'RandomForest'\n",
    "\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}\"),\n",
    "                                   imbalance=True)\n",
    "\n",
    "# set up pre-processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# store results as a list of tuples\n",
    "results = []\n",
    "\n",
    "# loop through each paramter and parameter value\n",
    "for key, values in random_tune.items():\n",
    "    # loop through each \n",
    "    for value in values:\n",
    "        \n",
    "        # set parameter and value to tune\n",
    "        parameter = { key : value }\n",
    "        \n",
    "        # perform random forest\n",
    "        mse, score, report = machine_learning.RandomForest(parameter_dict=parameter, regressor=False)\n",
    "        \n",
    "        results.append((key, value, mse, report['accuracy'], report['1']['precision'], \n",
    "                        report['1']['recall'], report['1']['f1-score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T15:17:38.191668Z",
     "start_time": "2020-08-12T15:17:38.176488Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 50, 'n_estimators': 20, 'max_features': 0.2, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "# store best result to be used as parameter\n",
    "best_results_dict = {}\n",
    "\n",
    "# loop through all parameter keys\n",
    "for key in random_tune.keys():\n",
    "    \n",
    "    # get the values for current key\n",
    "    values = [val for val in results if val[0] == key]\n",
    "    \n",
    "    # get the score for current key\n",
    "    scores = [val[6] for val in values]\n",
    "    \n",
    "    # get parameter for current key and max score\n",
    "    best_score = [val for val in values if val[6] == max(scores)]\n",
    "    \n",
    "    # set diction with best parameter and parameter value\n",
    "    best_results_dict[best_score[0][0]] = best_score[0][1]\n",
    "    \n",
    "# print best result\n",
    "print(best_results_dict)\n",
    "    \n",
    "# write results to file\n",
    "file_name = f\"{model}_best_results_dict.json\"\n",
    "json_data = json.dumps(best_results_dict)\n",
    "SetDict(file_name,json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T03:49:27.925265Z",
     "start_time": "2020-07-15T03:49:27.916470Z"
    }
   },
   "source": [
    "### Final, Tuned, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-12T15:17:38.967767Z",
     "start_time": "2020-08-12T15:17:38.196437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error is 0.07435039876511448 and accuracy is 0.9256496012348855 and precision is 0.9475108225108225 and         recall is 0.9475108225108225 and f1 is 0.9237668161434978\n"
     ]
    }
   ],
   "source": [
    "# store name to be use in results\n",
    "model = 'RandomForest'\n",
    "\n",
    "# call machine learning class\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}\"),\n",
    "                                   imbalance=True)\n",
    "# setup pre processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# get best_results_dict\n",
    "best_results_dict = GetDict(f\"{model}_best_results_dict.json\")  \n",
    "\n",
    "# perform random forest using best parameters\n",
    "mse, score, report = machine_learning.RandomForest(regressor=False, parameter_dict=best_results_dict)\n",
    "\n",
    "# print final model score\n",
    "print(f\"The mean squared error is {mse} and accuracy is {report['accuracy']} and precision is {report['1']['precision']} and \\\n",
    "        recall is {report['1']['precision']} and f1 is {report['1']['f1-score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-12T15:17:06.422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:58:16] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:17] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:18] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:19] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:19] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:20] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:21] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:22] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:22] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:22] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:23] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:24] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:24] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:26] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:28] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:31] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:32] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:32] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:32] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:32] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:32] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:33] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:33] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:33] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:34] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15:58:34] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:58:35] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set model name\n",
    "model = 'XGBoost'\n",
    "\n",
    "# call machine learning class\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}\"),\n",
    "                                   imbalance=True)\n",
    "\n",
    "# perform pre-processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# store results as a list of tuples\n",
    "results = []\n",
    "\n",
    "# loop through each paramter and parameter value\n",
    "for key, values in xgb_tune.items():\n",
    "    # loop through each\n",
    "    for value in values:\n",
    "\n",
    "        # set parameter and value to tune\n",
    "        parameter = {key: value}\n",
    "\n",
    "        # perform random forst\n",
    "        mse, score, report = machine_learning.XGboost(regressor=False, parameter_dict=parameter)\n",
    "\n",
    "        results.append((key, value, mse, report['accuracy'], report['1']['precision'], \n",
    "                        report['1']['recall'], report['1']['f1-score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-12T15:17:06.426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.6, 'max_depth': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# store best result to be used as parameter\n",
    "best_results_dict = {}\n",
    "\n",
    "# loop through all parameter keys\n",
    "for key in xgb_tune.keys():\n",
    "    \n",
    "    # get the values for current key\n",
    "    values = [val for val in results if val[0] == key]\n",
    "    \n",
    "    # get the score for current key\n",
    "    scores = [val[6] for val in values]\n",
    "    \n",
    "    # get parameter for current key and max score\n",
    "    best_score = [val for val in values if val[6] == max(scores)]\n",
    "    \n",
    "    # set diction with best parameter and parameter value\n",
    "    best_results_dict[best_score[0][0]] = best_score[0][1]\n",
    "    \n",
    "# print best result\n",
    "print(best_results_dict)\n",
    "    \n",
    "# write results to file\n",
    "file_name = f\"{model}_best_results_dict.json\"\n",
    "json_data = json.dumps(best_results_dict)\n",
    "SetDict(file_name,json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final, Tuned, XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-12T15:17:06.429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:58:36] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "The mean squared error is 0.0720349884229483 and accuracy is 0.9279650115770517 and precision is 0.940646528881823 and         recall is 0.940646528881823 and f1 is 0.926892950391645\n"
     ]
    }
   ],
   "source": [
    "# set model name\n",
    "model = 'XGBoost' \n",
    "\n",
    "# call machine learning class\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}\"),\n",
    "                                   imbalance=True)\n",
    " \n",
    "# setup pre processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# get best_results_dict\n",
    "best_results_dict = GetDict(f\"{model}_best_results_dict.json\")\n",
    "\n",
    "\n",
    "# # perform random forest using best parameters\n",
    "mse, score, report = machine_learning.XGboost(regressor=False, parameter_dict=best_results_dict)\n",
    "        \n",
    "# # print final model score\n",
    "print(f\"The mean squared error is {mse} and accuracy is {report['accuracy']} and precision is {report['1']['precision']} and \\\n",
    "        recall is {report['1']['precision']} and f1 is {report['1']['f1-score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LgBoost Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-12T15:17:06.432Z"
    }
   },
   "outputs": [],
   "source": [
    "# set model name\n",
    "model = 'LGBoost'\n",
    "\n",
    "# call machine learning class\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}\"),\n",
    "                                   imbalance=True)\n",
    " \n",
    "# set columns for preprocessing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# store results as a list of tuples\n",
    "results = []\n",
    "\n",
    "# loop through each paramter and parameter value\n",
    "for key, values in lgb_tune.items():\n",
    "    # loop through each \n",
    "    for value in values:\n",
    "        \n",
    "        # set parameter and value to tune\n",
    "        parameter = { key : value }\n",
    "        \n",
    "        # perform random forst\n",
    "        mse, score, report = machine_learning.LGboost(regressor=False, parameter_dict=parameter)\n",
    "        \n",
    "        results.append((key, value, mse, report['accuracy'], report['1']['precision'], \n",
    "                        report['1']['recall'], report['1']['f1-score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-12T15:17:06.434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.2, 'max_depth': 15, 'num_leaves': 31, 'n_estimators': 100, 'min_data_in_leaf': 100}\n"
     ]
    }
   ],
   "source": [
    "# store best result to be used as parameter\n",
    "best_results_dict = {}\n",
    "\n",
    "# loop through all parameter keys\n",
    "for key in lgb_tune.keys():\n",
    "\n",
    "    # get the values for current key\n",
    "    values = [val for val in results if val[0] == key]\n",
    "    \n",
    "    # get the score for current key\n",
    "    scores = [val[6] for val in values]\n",
    "    \n",
    "    # get parameter for current key and max score\n",
    "    best_score = [val for val in values if val[6] == max(scores)]\n",
    "    \n",
    "    # set diction with best parameter and parameter value\n",
    "    best_results_dict[best_score[0][0]] = best_score[0][1]\n",
    "\n",
    "# print out results\n",
    "print(best_results_dict)\n",
    "\n",
    "# write results to file\n",
    "file_name = f\"{model}_best_results_dict.json\"\n",
    "json_data = json.dumps(best_results_dict)\n",
    "SetDict(file_name,json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final, Tuned, LgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-12T15:17:06.437Z"
    }
   },
   "outputs": [],
   "source": [
    "# set model name\n",
    "model = 'LGBoost' \n",
    "\n",
    "# call machine learning class\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}\"),\n",
    "                                   imbalance=True)\n",
    " \n",
    "# setup pre processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# get best_results_dict\n",
    "best_results_dict = GetDict(f\"{model}_best_results_dict.json\")  \n",
    "\n",
    "\n",
    "# perform random forest using best parameters\n",
    "mse, score, report = machine_learning.LGboost(regressor=False, parameter_dict=best_results_dict)\n",
    "        \n",
    "# print final model score\n",
    "print(f\"The mean squared error is {mse} and accuracy is {report['accuracy']} and precision is {report['1']['precision']} and \\\n",
    "        recall is {report['1']['precision']} and f1 is {report['1']['f1-score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------ Test Models ------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-12T15:17:06.441Z"
    }
   },
   "outputs": [],
   "source": [
    "# store name to be use in results\n",
    "model = 'LogisticRegression'\n",
    "\n",
    "# store results for all models\n",
    "cv_results = {}\n",
    "\n",
    "# load data\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}_CrossValidation\"),\n",
    "                                   imbalance=True)\n",
    "\n",
    "# setup pre processing\n",
    "preprocessing=machine_learning.PreProcessing()\n",
    "\n",
    "# perform random forest using best parameters\n",
    "mse = machine_learning.LogisticRegression(cross_validation=True)\n",
    "\n",
    "# get max f1 score index\n",
    "index = np.argmax(mse[4])\n",
    "\n",
    "# get minimum mse and corresponding accuracy\n",
    "min_mse = mse[0][index]\n",
    "accuracy = mse[1][index]\n",
    "precision = mse[2][index]\n",
    "recall = mse[3][index]\n",
    "f1 = mse[4][index]\n",
    "\n",
    "# store final model score\n",
    "cv_results[model] = min_mse, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-12T15:17:06.446Z"
    }
   },
   "outputs": [],
   "source": [
    "# store name to be use in results\n",
    "model = 'RandomForest'\n",
    "\n",
    "# load data\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}_CrossValidation\"),\n",
    "                                   imbalance=True)\n",
    "\n",
    "# setup pre processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# get best_results_dict\n",
    "best_results_dict = GetDict(f\"{model}_best_results_dict.json\")  \n",
    "\n",
    "# perform random forest using best parameters\n",
    "mse = machine_learning.RandomForest(\n",
    "    parameter_dict=best_results_dict, regressor=False, cross_validation=True)\n",
    "\n",
    "# get max f1 score index\n",
    "index = np.argmax(mse[4])\n",
    "\n",
    "# get minimum mse and corresponding accuracy\n",
    "min_mse = mse[0][index]\n",
    "accuracy = mse[1][index]\n",
    "precision = mse[2][index]\n",
    "recall = mse[3][index]\n",
    "f1 = mse[4][index]\n",
    "\n",
    "# store final model score\n",
    "cv_results[model] = min_mse, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T04:29:53.743096Z",
     "start_time": "2020-07-15T04:29:53.740031Z"
    }
   },
   "source": [
    "## XgBoost Forest Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-12T15:17:06.449Z"
    }
   },
   "outputs": [],
   "source": [
    "# store name to be use in results\n",
    "model = 'XGBoost'\n",
    "\n",
    "# load data\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}_CrossValidation\"),\n",
    "                                   imbalance=True)\n",
    "\n",
    "# setup pre processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# get best_results_dict\n",
    "best_results_dict = GetDict(f\"{model}_best_results_dict.json\")  \n",
    "\n",
    "# perform random forest using best parameters\n",
    "mse = machine_learning.XGboost(\n",
    "    parameter_dict=best_results_dict, regressor=False, cross_validation=True)\n",
    "\n",
    "# get max f1 score index\n",
    "index = np.argmax(mse[4])\n",
    "\n",
    "# get minimum mse and corresponding accuracy\n",
    "min_mse = mse[0][index]\n",
    "accuracy = mse[1][index]\n",
    "precision = mse[2][index]\n",
    "recall = mse[3][index]\n",
    "f1 = mse[4][index]\n",
    "\n",
    "# store final model score\n",
    "cv_results[model] = min_mse, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LgBoost Forest Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-12T15:17:06.451Z"
    }
   },
   "outputs": [],
   "source": [
    "# store name to be use in results\n",
    "model = 'LGBoost'\n",
    "\n",
    "# load data\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}_CrossValidation\"),\n",
    "                                   imbalance=True)\n",
    "\n",
    "# setup pre processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# get best_results_dict\n",
    "best_results_dict = GetDict(f\"{model}_best_results_dict.json\")  \n",
    "\n",
    "# perform random forest using best parameters\n",
    "mse = machine_learning.LGboost(\n",
    "    parameter_dict=best_results_dict, regressor=False, cross_validation=True)\n",
    "\n",
    "# get max f1 score index\n",
    "index = np.argmax(mse[4])\n",
    "\n",
    "# get minimum mse and corresponding accuracy\n",
    "min_mse = mse[0][index]\n",
    "accuracy = mse[1][index]\n",
    "precision = mse[2][index]\n",
    "recall = mse[3][index]\n",
    "f1 = mse[4][index]\n",
    "\n",
    "# store final model score\n",
    "cv_results[model] = min_mse, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-12T15:17:06.455Z"
    }
   },
   "outputs": [],
   "source": [
    "# show model results\n",
    "model_dataframe = pd.DataFrame()\n",
    "model_dataframe['Model'] = cv_results.keys()\n",
    "model_dataframe['MeanSquaredError'] = [v[0] for v in cv_results.values()]\n",
    "model_dataframe['Accuracy'] = [v[1] for v in cv_results.values()]\n",
    "model_dataframe['Precision'] = [v[2] for v in cv_results.values()]\n",
    "model_dataframe['Recall'] = [v[3] for v in cv_results.values()]\n",
    "model_dataframe['F1'] = [v[4] for v in cv_results.values()]\n",
    "model_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-12T15:17:06.459Z"
    }
   },
   "outputs": [],
   "source": [
    "# write dataframe to file\n",
    "model_dataframe.to_csv(os.path.join('../logs','FinalResults.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T04:34:27.756703Z",
     "start_time": "2020-07-15T04:34:27.753878Z"
    }
   },
   "source": [
    "## Select best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-12T15:17:06.462Z"
    }
   },
   "outputs": [],
   "source": [
    "#select the model with the lowest error as your \"production\" model\n",
    "model_dataframe = pd.read_csv(os.path.join('../logs', 'FinalResults.csv'), low_memory=False)\n",
    "best_model = model_dataframe.loc[model_dataframe['F1'] == max(model_dataframe['F1'])]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-12T15:17:06.465Z"
    }
   },
   "outputs": [],
   "source": [
    "# store name to be use in results\n",
    "model = best_model['Model'].to_string(index=False).strip()\n",
    "\n",
    "# load data\n",
    "machine_learning = MachineLearning(train_data=os.path.join('../data','cleaned','procedure_data.tar.gz'), \n",
    "                                   label='UnpaidClaim',\n",
    "                                   log_file=os.path.join('../logs', f\"{model}_FinalModel\"),\n",
    "                                   imbalance=True)\n",
    "\n",
    "# setup pre processing\n",
    "preprocessing = machine_learning.PreProcessing()\n",
    "\n",
    "# choose the best model and save the model\n",
    "if model == 'LogisticRegression':\n",
    "    machine_learning.LogisticRegression(save_model=True)\n",
    "elif model == 'RandomForest':\n",
    "    best_results_dict = GetDict(f\"{model}_best_results_dict.json\")  \n",
    "    machine_learning.RandomForest(\n",
    "        parameter_dict=best_results_dict, regressor=False, save_model=True)\n",
    "elif model == 'XGBoost':\n",
    "    best_results_dict = GetDict(f\"{model}_best_results_dict.json\")  \n",
    "    machine_learning.XGboost(parameter_dict=best_results_dict, regressor=False, save_model=True)\n",
    "elif model == 'LGBoost':\n",
    "    best_results_dict = GetDict(f\"{model}_best_results_dict.json\")  \n",
    "    machine_learning.LGboost(parameter_dict=best_results_dict, regressor=False, save_model=True)\n",
    "else:\n",
    "    print(f'{model} not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-12T15:17:06.468Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# store name to be use in results\n",
    "model_name = best_model['Model'].to_string(index=False).strip()\n",
    "\n",
    "# plot feature importance for the best model\n",
    "FeatureImportance(model=model_name);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (claims)",
   "language": "python",
   "name": "claims"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
